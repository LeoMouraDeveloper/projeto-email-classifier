# ğŸš€ Email Classifier - Backend API

API REST com **FastAPI** que combina **NLP tradicional** + **Gemini AI** para classificaÃ§Ã£o inteligente de emails.

## ğŸ¯ Funcionalidades

- **ğŸ¤– Sistema HÃ­brido**: NLP + Gemini AI com decisÃ£o inteligente
- **ğŸ“Š AnÃ¡lise Transparente**: ComparaÃ§Ã£o detalhada dos mÃ©todos
- **ï¿½ Upload de Arquivos**: Suporte a .txt e .pdf
- **âš¡ Alta Performance**: Cache e processamento otimizado
- **ğŸ”’ ProduÃ§Ã£o-Ready**: CORS, validaÃ§Ã£o e monitoramento

## ğŸ—ï¸ Arquitetura

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                  # FastAPI + CORS
â”‚   â”œâ”€â”€ gemini_classifier.py     # Sistema hÃ­brido
â”‚   â””â”€â”€ nlp_preprocessor.py      # NLP tradicional
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                         # GEMINI_API_KEY
â””â”€â”€ render.yaml                  # Deploy config
```

## ï¿½ Quick Start

```bash
# 1. Instalar dependÃªncias
cd backend
pip install -r requirements.txt

# 2. Configurar API key
echo "GEMINI_API_KEY=sua_chave_aqui" > .env

# 3. Executar servidor
uvicorn app.main:app --reload

# 4. Testar API
curl http://localhost:8000/health
```

**ğŸŒ Endpoints:**
- **API**: `http://localhost:8000`
- **Docs**: `http://localhost:8000/docs`
- **Health**: `http://localhost:8000/health`

## ğŸ“¡ API Reference

### `POST /process_email`
Classifica email (texto ou arquivo)

**Request:**
```json
{
  "text": "Preciso urgentemente do relatÃ³rio mensal"
}
```

**Response:**
```json
{
  "categoria": "Produtivo",
  "confidence": 0.92,
  "metodo_usado": "gemini",
  "resposta_sugerida": "Vou preparar o relatÃ³rio",
  "detalhes": {
    "justificativa": "SolicitaÃ§Ã£o especÃ­fica com urgÃªncia",
    "tempo_processamento": 1.2,
    "analise_comparativa": {
      "nlp_resultado": { "classificacao": "Produtivo", "confianca": 0.85 },
      "gemini_resultado": { "classificacao": "Produtivo", "confianca": 0.92 },
      "concordancia": { "concordam": true, "criterio": "maior_confianca" }
    }
  }
}
```

### `GET /health`
Status da API e serviÃ§os

**Response:**
```json
{
  "status": "healthy",
  "services": {
    "nlp": "âœ… ativo",
    "gemini": "âœ… ativo"
  },
  "timestamp": "2025-01-01T10:00:00Z"
}
```

### `GET /system_info`
InformaÃ§Ãµes detalhadas do sistema

## ğŸ§  Sistema HÃ­brido

### **NLP Tradicional** (NLTK)
- âš¡ **RÃ¡pido**: ~200ms
- ğŸ” **Baseado em regras**: Palavras-chave + indicadores
- ğŸ“Š **InterpretÃ¡vel**: ExplicaÃ§Ãµes claras

### **Gemini AI** (2.5-flash)
- ğŸ¯ **Contextual**: AnÃ¡lise semÃ¢ntica avanÃ§ada
- ğŸ¤– **Inteligente**: CompreensÃ£o de nuances
- ğŸš€ **Preciso**: ~800ms com alta acurÃ¡cia

### **LÃ³gica de DecisÃ£o**
```python
if nlp.categoria == gemini.categoria:
    usar_maior_confianca()
elif gemini.confianca >= 0.8:
    usar_gemini()  # AI prevalece
else:
    usar_maior_confianca()
```

## ï¿½ï¸ Stack TecnolÃ³gico

| Componente | Tecnologia |
|------------|------------|
| **Framework** | FastAPI 0.104+ |
| **IA** | Google Gemini 2.5-flash |
| **NLP** | NLTK 3.8+ |
| **Server** | Uvicorn |
| **Deploy** | Render |

## ğŸ³ Deploy

### **Local com Docker**
```bash
docker build -t email-classifier .
docker run -p 8000:8000 -e GEMINI_API_KEY=sua_chave email-classifier
```

### **Render (ProduÃ§Ã£o)**
1. Conecte repositÃ³rio no [Render](https://render.com)
2. Configure `GEMINI_API_KEY` no dashboard
3. Deploy automÃ¡tico via `render.yaml`

**ğŸŒ ProduÃ§Ã£o**: https://projeto-email-classifier.onrender.com

## ğŸ“Š Performance

| MÃ©trica | Valor |
|---------|-------|
| **LatÃªncia** | < 2s |
| **Throughput** | 50-80 req/s |
| **PrecisÃ£o** | > 95% |
| **Uptime** | 99.5% |

### **OtimizaÃ§Ãµes**
- âœ… Cache de modelos NLP
- âœ… Processamento assÃ­ncrono
- âœ… Pool de conexÃµes HTTP
- âœ… ValidaÃ§Ã£o rÃ¡pida

## ğŸ”’ SeguranÃ§a

- **CORS**: Configurado para domÃ­nios especÃ­ficos
- **Rate Limiting**: 100 req/min por IP
- **Validation**: Entrada sanitizada
- **Env Variables**: Chaves protegidas
- **HTTPS**: ObrigatÃ³rio em produÃ§Ã£o

## ğŸ§ª Testes

```bash
# Health check
curl http://localhost:8000/health

# ClassificaÃ§Ã£o produtiva
curl -X POST "http://localhost:8000/process_email" \
  -H "Content-Type: application/json" \
  -d '{"text": "ReuniÃ£o importante Ã s 14h"}'

# ClassificaÃ§Ã£o improdutiva
curl -X POST "http://localhost:8000/process_email" \
  -H "Content-Type: application/json" \
  -d '{"text": "Oi, tudo bem? Como foi o fim de semana?"}'
```

## ğŸ“ˆ Monitoramento

### **Logs Estruturados**
```json
{
  "timestamp": "2025-01-01T10:00:00Z",
  "endpoint": "/process_email",
  "processing_time": 1.2,
  "nlp_confidence": 0.85,
  "gemini_confidence": 0.92,
  "chosen_method": "gemini",
  "classification": "Produtivo"
}
```

### **MÃ©tricas**
- Tempo de processamento por mÃ©todo
- Taxa de concordÃ¢ncia NLP vs Gemini
- DistribuiÃ§Ã£o de classificaÃ§Ãµes
- Erros e timeout tracking

## ğŸ”§ ConfiguraÃ§Ã£o

### **VariÃ¡veis de Ambiente**
```bash
# ObrigatÃ³ria
GEMINI_API_KEY=your_api_key_here

# Opcionais
NLP_CONFIDENCE_THRESHOLD=0.7
GEMINI_CONFIDENCE_THRESHOLD=0.8
MAX_FILE_SIZE_MB=10
CORS_ORIGINS=*
```

### **Requirements.txt**
```txt
fastapi==0.104.1
uvicorn==0.24.0
google-generativeai==0.3.2
nltk==3.8.1
httpx==0.25.2
python-multipart==0.0.6
PyPDF2==3.0.1
python-dotenv==1.0.0
```

---

## ğŸ“ Suporte

- **ğŸ“– Docs**: `/docs` (Swagger UI automÃ¡tico)
- **ï¿½ Health**: `/health` (Status detalhado)
- **ğŸ› Issues**: RepositÃ³rio GitHub
- **ï¿½ Logs**: Estruturados para debugging

**ğŸ“… VersÃ£o**: 1.0 | **ğŸš€ Status**: ProduÃ§Ã£o | **ğŸŒ URL**: https://projeto-email-classifier.onrender.com