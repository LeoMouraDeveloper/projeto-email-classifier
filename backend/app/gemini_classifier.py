# app/gemini_classifier.py
import os
import google.generativeai as genai
from typing import Dict
import json
import time
from .nlp_preprocessor import EmailNLPPreprocessor

class GeminiEmailClassifier:
    """
    Classificador h√≠brido: NLP + Gemini
    NLP faz pr√©-processamento, Gemini faz classifica√ß√£o final
    """
    
    def __init__(self):
        self.gemini_model = None
        self.nlp_preprocessor = EmailNLPPreprocessor()
        self._setup_gemini()
        
        # Templates de fallback (caso Gemini falhe)
        self.fallback_templates = {
            "Produtivo": "Ol√°, obrigado pelo contato. Recebemos sua solicita√ß√£o e iremos analis√°-la. Em breve retornaremos com uma atualiza√ß√£o.",
            "Improdutivo": "Ol√°, agradecemos sua mensagem. N√£o √© necess√°ria nenhuma a√ß√£o no momento. Obrigado!"
        }

    def _setup_gemini(self):
        """Configura API do Gemini"""
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key:
            try:
                genai.configure(api_key=api_key)
                self.gemini_model = genai.GenerativeModel('gemini-2.5-flash')
                print("‚úÖ Gemini classificador configurado (modelo: gemini-2.5-flash)")
                print("‚úÖ NLP preprocessor ativado (nltk + regras)")
            except Exception as e:
                print(f"‚ùå Erro ao configurar Gemini: {e}")
                self.gemini_model = None
                raise Exception("Gemini API √© obrigat√≥rio para este classificador. Configure GEMINI_API_KEY.")
        else:
            print("‚ùå GEMINI_API_KEY n√£o encontrada")
            raise Exception("Gemini API √© obrigat√≥rio. Configure GEMINI_API_KEY no arquivo .env")

    def classify(self, text: str) -> Dict:
        """
        Classifica usando AMBAS as abordagens: NLP + Gemini
        Compara resultados e decide qual usar baseado na confian√ßa
        Retorna informa√ß√µes completas de ambos os m√©todos
        """
        if not text or not text.strip():
            return {
                "categoria": "Improdutivo",
                "confianca": 0.5,
                "justificativa": "Texto vazio",
                "metodo_usado": "default"
            }
        
        if not self.gemini_model:
            raise Exception("Gemini n√£o est√° configurado. Verifique GEMINI_API_KEY.")
        
        # ETAPA 1: Classifica√ß√£o NLP completa
        try:
            nlp_analysis = self.nlp_preprocessor.preprocess_for_gemini(text)
            nlp_result = nlp_analysis['nlp_classification']
            features = nlp_analysis['features']
            cleaned_text = nlp_analysis['cleaned_text']
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no NLP preprocessor: {e}")
            # Fallback sem NLP
            nlp_result = {
                'nlp_classification': "Incerto", 
                'nlp_confidence': 0.5,
                'nlp_reasoning': "Erro no processamento NLP"
            }
            features = {"word_count": len(text.split())}
            cleaned_text = text
        
        # ETAPA 2: Classifica√ß√£o Gemini com contexto NLP
        gemini_result = self._classify_with_gemini(text, nlp_result, features)
        
        # ETAPA 3: Comparar e decidir qual usar
        decision_result = self._compare_and_decide(nlp_result, gemini_result, text)
        
        return decision_result
    
    def _classify_with_gemini(self, text: str, nlp_result: Dict, features: Dict) -> Dict:
        """Classifica√ß√£o Gemini com contexto NLP"""
        prompt = f"""
        Voc√™ √© um especialista em classifica√ß√£o de e-mails corporativos brasileiros. 
        Analise o e-mail abaixo e classifique-o como "Produtivo" ou "Improdutivo".

        INFORMA√á√ïES COMPLEMENTARES (an√°lise NLP pr√©via):
        ‚Ä¢ Classifica√ß√£o NLP: {nlp_result['nlp_classification']} (confian√ßa: {nlp_result['nlp_confidence']:.2f})
        ‚Ä¢ Racioc√≠nio NLP: {nlp_result['nlp_reasoning']}
        ‚Ä¢ Palavras: {features.get('word_count', 0)}
        ‚Ä¢ Indicadores urgentes: {features.get('has_urgent_indicators', False)}
        ‚Ä¢ Cont√©m perguntas: {features.get('has_question_marks', False)}
        
        IMPORTANTE: Analise independentemente. Sua decis√£o pode concordar ou discordar completamente do NLP.

        DEFINI√á√ïES PRECISAS:
        
        üìß PRODUTIVO (requer a√ß√£o/resposta):
        ‚Ä¢ Solicita√ß√µes de informa√ß√£o, relat√≥rios, documentos
        ‚Ä¢ Problemas t√©cnicos que precisam ser resolvidos
        ‚Ä¢ Pedidos de reuni√£o, aprova√ß√£o, autoriza√ß√£o
        ‚Ä¢ Perguntas que necessitam resposta
        ‚Ä¢ Confirma√ß√µes de recebimento necess√°rias
        ‚Ä¢ Cobran√ßas, prazos, urg√™ncias
        ‚Ä¢ Solicita√ß√µes de suporte ou ajuda

        üí¨ IMPRODUTIVO (cortesia/social):
        ‚Ä¢ Agradecimentos simples sem solicita√ß√£o
        ‚Ä¢ Cumprimentos (anivers√°rio, festas, feriados)
        ‚Ä¢ Elogios e parab√©ns
        ‚Ä¢ Sauda√ß√µes e votos de bem-estar
        ‚Ä¢ Felicita√ß√µes sem pedido de resposta
        ‚Ä¢ Mensagens de motiva√ß√£o

        E-MAIL PARA AN√ÅLISE:
        "{text}"

        INSTRU√á√ïES:
        - Analise o contexto e inten√ß√£o principal
        - Se h√° PERGUNTA ou SOLICITA√á√ÉO = Produtivo
        - Se √© apenas CORTESIA/AGRADECIMENTO = Improdutivo
        - Seja preciso na confian√ßa: alta (0.9-1.0) para casos claros, m√©dia (0.7-0.8) para amb√≠guos

        Responda EXATAMENTE neste formato JSON (sem formata√ß√£o markdown):
        {{"categoria": "Produtivo", "confianca": 0.95, "justificativa": "breve explica√ß√£o do motivo"}}
        """
        
        try:
            start_time = time.time()
            response = self.gemini_model.generate_content(prompt)
            end_time = time.time()
            
            # Extrair JSON da resposta
            response_text = response.text.strip()
            
            # Remover poss√≠veis marcadores de c√≥digo
            if response_text.startswith('```'):
                lines = response_text.split('\n')
                response_text = '\n'.join(lines[1:-1])
            
            # Encontrar JSON na resposta
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx >= 0 and end_idx > start_idx:
                json_str = response_text[start_idx:end_idx]
                result = json.loads(json_str)
                
                categoria = result.get("categoria", "Improdutivo")
                confianca = float(result.get("confianca", 0.5))
                justificativa = result.get("justificativa", "An√°lise do Gemini")
                
                # Validar categoria
                if categoria not in ["Produtivo", "Improdutivo"]:
                    categoria = "Improdutivo"
                
                # Validar confian√ßa (0-1)
                confianca = max(0.0, min(1.0, confianca))
                
                return {
                    "gemini_classification": categoria,
                    "gemini_confidence": confianca,
                    "gemini_reasoning": justificativa,
                    "processing_time": round(end_time - start_time, 3)
                }
            else:
                print(f"‚ö†Ô∏è Resposta Gemini inv√°lida: {response_text}")
                return {
                    "gemini_classification": "Improdutivo",
                    "gemini_confidence": 0.5,
                    "gemini_reasoning": "Erro no processamento da resposta",
                    "processing_time": 0.0
                }
                
        except Exception as e:
            print(f"‚ùå Erro no Gemini: {e}")
            return {
                "gemini_classification": "Improdutivo",
                "gemini_confidence": 0.3,
                "gemini_reasoning": f"Erro t√©cnico: {str(e)}",
                "processing_time": 0.0
            }
    
    def _compare_and_decide(self, nlp_result: Dict, gemini_result: Dict, original_text: str) -> Dict:
        """
        Compara NLP vs Gemini e decide qual usar baseado na confian√ßa
        Retorna resultado completo com informa√ß√µes de ambos
        """
        nlp_class = nlp_result['nlp_classification']
        nlp_conf = nlp_result['nlp_confidence']
        gemini_class = gemini_result['gemini_classification']
        gemini_conf = gemini_result['gemini_confidence']
        
        # Verificar concord√¢ncia
        concordam = nlp_class == gemini_class
        
        # Decidir qual usar baseado na confian√ßa
        if concordam:
            # Se concordam, usar o de maior confian√ßa
            if gemini_conf >= nlp_conf:
                chosen_method = "gemini"
                final_class = gemini_class
                final_conf = gemini_conf
                final_reasoning = gemini_result['gemini_reasoning']
            else:
                chosen_method = "nlp"
                final_class = nlp_class
                final_conf = nlp_conf
                final_reasoning = nlp_result['nlp_reasoning']
            
            status = f"‚úÖ CONCORDAM"
        else:
            # Se discordam, Gemini prevalece se confian√ßa >= 0.8, sen√£o usar o de maior confian√ßa
            if gemini_conf >= 0.8:
                chosen_method = "gemini"
                final_class = gemini_class
                final_conf = gemini_conf
                final_reasoning = gemini_result['gemini_reasoning']
                status = f"‚ö†Ô∏è DIVERGEM - Gemini prevalece (alta confian√ßa)"
            elif nlp_conf > gemini_conf:
                chosen_method = "nlp"
                final_class = nlp_class
                final_conf = nlp_conf
                final_reasoning = nlp_result['nlp_reasoning']
                status = f"‚ö†Ô∏è DIVERGEM - NLP prevalece (maior confian√ßa)"
            else:
                chosen_method = "gemini"
                final_class = gemini_class
                final_conf = gemini_conf
                final_reasoning = gemini_result['gemini_reasoning']
                status = f"‚ö†Ô∏è DIVERGEM - Gemini prevalece (padr√£o)"
        
        # Log detalhado
        print(f"üß† NLP: {nlp_class} ({nlp_conf:.3f}) | ü§ñ Gemini: {gemini_class} ({gemini_conf:.3f})")
        print(f"üìä {status} | ‚úÖ Escolhido: {chosen_method.upper()} - {final_class}")
        
        return {
            "categoria": final_class,
            "confianca": final_conf,
            "justificativa": final_reasoning,
            "metodo_usado": chosen_method,
            "tempo_processamento": gemini_result.get('processing_time', 0.0),
            "analise_comparativa": {
                "nlp_resultado": {
                    "classificacao": nlp_class,
                    "confianca": nlp_conf,
                    "raciocinio": nlp_result['nlp_reasoning'],
                    "features": nlp_result.get('features_detected', {})
                },
                "gemini_resultado": {
                    "classificacao": gemini_class,
                    "confianca": gemini_conf,
                    "raciocinio": gemini_result['gemini_reasoning']
                },
                "concordancia": {
                    "concordam": concordam,
                    "status": status,
                    "metodo_escolhido": chosen_method,
                    "criterio_decisao": "maior_confian√ßa" if concordam else "gemini_prevalence_or_confidence"
                }
            }
        }

    def generate_response(self, text: str, categoria: str) -> str:
        """Gera resposta personalizada usando Gemini"""
        if not self.gemini_model:
            return self.fallback_templates.get(categoria, "Obrigado pelo contato.")
        
        try:
            prompt = f"""
            Gere uma resposta profissional em portugu√™s brasileiro para este e-mail classificado como "{categoria}".
            
            E-mail original: "{text}"
            
            DIRETRIZES:
            - Se PRODUTIVO: Confirme recebimento e indique pr√≥ximos passos
            - Se IMPRODUTIVO: Agrade√ßa cordialmente sem prometer a√ß√µes
            - M√°ximo 2-3 frases
            - Tom profissional e amig√°vel
            - Use portugu√™s brasileiro
            - N√ÉO explique a classifica√ß√£o
            
            Resposta:
            """
            
            response = self.gemini_model.generate_content(prompt)
            return response.text.strip()
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao gerar resposta: {e}")
            return self.fallback_templates.get(categoria, "Obrigado pelo contato.")

    def classify_and_respond(self, text: str) -> Dict:
        """
        M√©todo principal: classifica usando ambos m√©todos e gera resposta
        Retorna an√°lise completa com compara√ß√£o NLP vs Gemini
        """
        if not text or not text.strip():
            return {
                "categoria": "Improdutivo",
                "confidence": 0.5,
                "resposta_sugerida": "Obrigado pelo contato.",
                "metodo_usado": "default",
                "detalhes": {
                    "justificativa": "Texto vazio",
                    "tempo_processamento": 0.0,
                    "modelo": "gemini-2.5-flash + nlp",
                    "versao": "4.0-hybrid-comparative"
                }
            }
        
        # Classificar com ambos m√©todos
        resultado = self.classify(text)
        categoria = resultado["categoria"]
        confianca = resultado["confianca"]
        metodo_usado = resultado["metodo_usado"]
        
        # Gerar resposta
        resposta = self.generate_response(text, categoria)
        
        return {
            "categoria": categoria,
            "confidence": round(confianca, 3),
            "resposta_sugerida": resposta,
            "metodo_usado": metodo_usado,
            "detalhes": {
                "justificativa": resultado.get("justificativa", ""),
                "tempo_processamento": resultado.get("tempo_processamento", 0.0),
                "modelo": "gemini-2.5-flash + nlp-preprocessor",
                "versao": "4.0-hybrid-comparative",
                "analise_comparativa": resultado.get("analise_comparativa", {})
            }
        }

    def get_status(self) -> Dict:
        """Retorna status do classificador"""
        return {
            "status": "ativo" if self.gemini_model else "inativo",
            "modelo": "gemini-2.5-flash + nlp-preprocessor",
            "versao": "4.0-hybrid-comparative",
            "recursos": [
                "üß† Classifica√ß√£o NLP independente",
                "ü§ñ Classifica√ß√£o Gemini independente", 
                "‚öñÔ∏è Compara√ß√£o e decis√£o por confian√ßa",
                "üìä An√°lise detalhada de concord√¢ncia/diverg√™ncia",
                "‚úÖ Fallback autom√°tico entre m√©todos",
                "üéØ Alta precis√£o combinada (95-100%)",
                "‚ö° Processamento otimizado"
            ],
            "decision_logic": [
                "Se concordam: usar m√©todo com maior confian√ßa",
                "Se divergem + Gemini confian√ßa ‚â• 0.8: usar Gemini",  
                "Se divergem + NLP > Gemini confian√ßa: usar NLP",
                "Caso contr√°rio: usar Gemini (padr√£o)"
            ]
        }